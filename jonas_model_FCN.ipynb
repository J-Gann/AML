{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import time\n",
    "import uuid\n",
    "import optuna\n",
    "import plotly\n",
    "import matplotlib\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datloader for the amex dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmericanExpressPreprocessedProfileTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataset_file, test=False, nrows=False, transformation=False):\n",
    "        data = np.load(dataset_file)\n",
    "        if not test:\n",
    "            num_data = data[\"train_floats\"].reshape(data[\"train_floats\"].shape[0], -1, 13)\n",
    "            cat_data = data[\"train_cat\"].reshape(data[\"train_cat\"].shape[0], -1, 13)\n",
    "            self.y = data[\"train_y\"]\n",
    "        else:\n",
    "            num_data = data[\"test_floats\"].reshape(data[\"test_floats\"].shape[0], -1, 13)\n",
    "            cat_data = data[\"test_cat\"].reshape(data[\"test_cat\"].shape[0], -1, 13)\n",
    "            self.y = data[\"test_y\"]\n",
    "\n",
    "        if nrows:\n",
    "            num_data = num_data[0:nrows]\n",
    "            cat_data = cat_data[0:nrows]\n",
    "            self.y = self.y[0:nrows]\n",
    "\n",
    "        self.dataset = np.concatenate([num_data, cat_data], axis=1)\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        data = torch.tensor(data, dtype=torch.float32, requires_grad=True)\n",
    "        label = torch.tensor([label], dtype=torch.float32)\n",
    "        label = label.to(device)\n",
    "        data = data.to(device)\n",
    "        if self.transformation: data = self.transformation(data)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN for time series classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        self.trial = trial\n",
    "\n",
    "        lin_activation = trial.suggest_categorical(f\"activation_lin\", [\"LeakyReLU\", \"ReLU\", \"ELU\"])\n",
    "        self.lin_activ = getattr(nn, lin_activation)()\n",
    "\n",
    "        self.linear = nn.Sequential()\n",
    "        linear_in = 2314\n",
    "        n_layers_linear = self.trial.suggest_int(\"n_layers_linear\", 1, 10)\n",
    "        for k in range(n_layers_linear):\n",
    "            linear_out = self.trial.suggest_int(f\"linear_size_layer{k}\", 100, 300, 10)\n",
    "            self.linear.append(nn.Linear(linear_in, linear_out))\n",
    "            self.linear.append(self.lin_activ)\n",
    "            batchnorm = self.trial.suggest_categorical(f\"linear_batchnorm_layer{k}\", [True, False])            \n",
    "            if batchnorm: self.linear.append(nn.BatchNorm1d(linear_out))\n",
    "\n",
    "            linear_in = linear_out\n",
    "        self.linear.append(nn.Linear(linear_out, 1))\n",
    "        self.linear.append(nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred = torch.round(pred)\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ration = 0.7\n",
    "full_dataset = AmericanExpressPreprocessedProfileTimeSeriesDataset(\"./amex_preprocessed.npz\", nrows=10000)\n",
    "\n",
    "train_size = int(train_test_ration * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = FCN(trial).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 0.1, log=True)\n",
    "    optim_ = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"Adam\", \"SGD\", \"Adagrad\", \"NAdam\"])\n",
    "    optimizer = getattr(optim, optim_)(model.parameters(), lr=lr)\n",
    "    lr_lambda = trial.suggest_float(\"lr_lambda\", 0.4, 0.99)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 128, 16)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: lr_lambda)\n",
    "    epochs = trial.suggest_int(\"epochs\", 1, 3)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
    "        loss = test_loop(test_dataloader, model, loss_fn, t)\n",
    "        trial.report(loss, t)\n",
    "        scheduler.step()\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-22 16:13:42,505]\u001b[0m A new study created in RDB with name: optuna-study-linear\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"optuna-study-linear\", direction=\"minimize\", storage='sqlite:///optuna-study-linear.db', load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-22 16:13:54,267]\u001b[0m Trial 0 finished with value: 0.3127328543751328 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 300, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 300, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 120, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 250, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 220, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 170, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 270, 'linear_batchnorm_layer6': False, 'lr': 0.0023921323508770127, 'optimizer': 'NAdam', 'lr_lambda': 0.9882088578300702, 'batch_size': 112, 'epochs': 3}. Best is trial 0 with value: 0.3127328543751328.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:13:58,566]\u001b[0m Trial 1 finished with value: 0.6678012178299275 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 10, 'linear_size_layer0': 250, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 180, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 160, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 150, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 260, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 170, 'linear_batchnorm_layer7': False, 'linear_size_layer8': 220, 'linear_batchnorm_layer8': False, 'linear_size_layer9': 130, 'linear_batchnorm_layer9': False, 'lr': 6.384774071516106e-05, 'optimizer': 'Adagrad', 'lr_lambda': 0.4199066035256654, 'batch_size': 64, 'epochs': 1}. Best is trial 0 with value: 0.3127328543751328.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:08,738]\u001b[0m Trial 2 finished with value: 0.6911247042899437 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 10, 'linear_size_layer0': 240, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 210, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 130, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 260, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 160, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 230, 'linear_batchnorm_layer5': True, 'linear_size_layer6': 120, 'linear_batchnorm_layer6': False, 'linear_size_layer7': 170, 'linear_batchnorm_layer7': False, 'linear_size_layer8': 270, 'linear_batchnorm_layer8': False, 'linear_size_layer9': 270, 'linear_batchnorm_layer9': True, 'lr': 1.1128087175307796e-06, 'optimizer': 'AdamW', 'lr_lambda': 0.6689016634571413, 'batch_size': 64, 'epochs': 2}. Best is trial 0 with value: 0.3127328543751328.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:14,957]\u001b[0m Trial 3 finished with value: 0.4133034778965844 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 4, 'linear_size_layer0': 110, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 260, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 180, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 210, 'linear_batchnorm_layer3': False, 'lr': 2.9435296349428787e-05, 'optimizer': 'AdamW', 'lr_lambda': 0.6974643023257217, 'batch_size': 112, 'epochs': 2}. Best is trial 0 with value: 0.3127328543751328.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:21,631]\u001b[0m Trial 4 finished with value: 0.6209458614152575 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 1, 'linear_size_layer0': 290, 'linear_batchnorm_layer0': True, 'lr': 3.629368751468162e-05, 'optimizer': 'SGD', 'lr_lambda': 0.9497092418786733, 'batch_size': 48, 'epochs': 2}. Best is trial 0 with value: 0.3127328543751328.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:28,160]\u001b[0m Trial 5 finished with value: 0.3834562301635742 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 3, 'linear_size_layer0': 180, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 110, 'linear_batchnorm_layer2': True, 'lr': 9.454271285207231e-05, 'optimizer': 'Adam', 'lr_lambda': 0.957081668600788, 'batch_size': 112, 'epochs': 2}. Best is trial 0 with value: 0.3127328543751328.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:37,883]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:45,667]\u001b[0m Trial 7 finished with value: 0.31271930280676546 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 8, 'linear_size_layer0': 200, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 140, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 290, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 170, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 170, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 160, 'linear_batchnorm_layer5': True, 'linear_size_layer6': 300, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 150, 'linear_batchnorm_layer7': True, 'lr': 0.012052761607883475, 'optimizer': 'NAdam', 'lr_lambda': 0.798546203164596, 'batch_size': 16, 'epochs': 1}. Best is trial 7 with value: 0.31271930280676546.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:54,644]\u001b[0m Trial 8 finished with value: 0.40190881348036706 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 3, 'linear_size_layer0': 270, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 170, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': False, 'lr': 9.034771336172168e-06, 'optimizer': 'Adam', 'lr_lambda': 0.409527980281325, 'batch_size': 16, 'epochs': 2}. Best is trial 7 with value: 0.31271930280676546.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:14:57,846]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:15:05,770]\u001b[0m Trial 10 finished with value: 0.31966235036862656 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 8, 'linear_size_layer0': 220, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 160, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 300, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 150, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 280, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 100, 'linear_batchnorm_layer5': True, 'linear_size_layer6': 170, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 290, 'linear_batchnorm_layer7': True, 'lr': 0.0030664103938002796, 'optimizer': 'NAdam', 'lr_lambda': 0.7840234352375989, 'batch_size': 16, 'epochs': 1}. Best is trial 7 with value: 0.31271930280676546.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:15:19,688]\u001b[0m Trial 11 finished with value: 0.31928687111327525 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 190, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 230, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 250, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 240, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 170, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 300, 'linear_batchnorm_layer6': False, 'lr': 0.002741059130574105, 'optimizer': 'NAdam', 'lr_lambda': 0.8305342959482432, 'batch_size': 80, 'epochs': 3}. Best is trial 7 with value: 0.31271930280676546.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:15:34,510]\u001b[0m Trial 12 finished with value: 0.29289246992544926 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 8, 'linear_size_layer0': 160, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 300, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 240, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 160, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 100, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 190, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 260, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 100, 'linear_batchnorm_layer7': True, 'lr': 0.002870078109726818, 'optimizer': 'NAdam', 'lr_lambda': 0.8292392338240753, 'batch_size': 32, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:15:54,280]\u001b[0m Trial 13 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:16:09,136]\u001b[0m Trial 14 finished with value: 0.30418963437067703 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 8, 'linear_size_layer0': 160, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 240, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 240, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 160, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 100, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 130, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 300, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 100, 'linear_batchnorm_layer7': True, 'lr': 0.012689035203479093, 'optimizer': 'NAdam', 'lr_lambda': 0.6654481018500472, 'batch_size': 32, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:16:20,253]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:16:40,534]\u001b[0m Trial 16 finished with value: 0.33425774567938865 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 8, 'linear_size_layer0': 170, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 300, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 210, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 130, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 120, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 300, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 210, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 100, 'linear_batchnorm_layer7': True, 'lr': 0.0006795530996162554, 'optimizer': 'NAdam', 'lr_lambda': 0.6666811935847492, 'batch_size': 32, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:16:50,668]\u001b[0m Trial 17 finished with value: 0.3053312376141548 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 130, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 210, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 260, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 190, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 140, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 130, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 250, 'linear_batchnorm_layer6': True, 'lr': 0.012363843897540678, 'optimizer': 'NAdam', 'lr_lambda': 0.5593235919767903, 'batch_size': 80, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:17:08,130]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:17:20,562]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:17:32,379]\u001b[0m Trial 20 finished with value: 0.3010080467830313 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 5, 'linear_size_layer0': 170, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 280, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 140, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 130, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 200, 'linear_batchnorm_layer4': True, 'lr': 0.08474463219487233, 'optimizer': 'AdamW', 'lr_lambda': 0.8987310401598031, 'batch_size': 32, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:17:48,275]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:17:59,457]\u001b[0m Trial 22 finished with value: 0.3433379159560279 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 5, 'linear_size_layer0': 130, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 280, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 200, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 130, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 250, 'linear_batchnorm_layer4': True, 'lr': 0.004797117932123395, 'optimizer': 'AdamW', 'lr_lambda': 0.896297190510155, 'batch_size': 48, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:18:17,226]\u001b[0m Trial 23 finished with value: 0.3042424430159178 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 6, 'linear_size_layer0': 160, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 230, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 230, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 170, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 100, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 130, 'linear_batchnorm_layer5': False, 'lr': 0.027837520342122803, 'optimizer': 'AdamW', 'lr_lambda': 0.7559705149355163, 'batch_size': 16, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:18:28,578]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:18:40,078]\u001b[0m Trial 25 finished with value: 0.30776774835713366 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 4, 'linear_size_layer0': 220, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 270, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 140, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 160, 'linear_batchnorm_layer3': True, 'lr': 0.007414671266259602, 'optimizer': 'AdamW', 'lr_lambda': 0.6248636050834429, 'batch_size': 32, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:18:49,712]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:19:06,330]\u001b[0m Trial 27 finished with value: 0.30281817976464614 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 8, 'linear_size_layer0': 140, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 280, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 100, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 200, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 130, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 130, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 300, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 230, 'linear_batchnorm_layer7': True, 'lr': 0.0014108022796342663, 'optimizer': 'NAdam', 'lr_lambda': 0.9250276483490857, 'batch_size': 32, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:19:21,442]\u001b[0m Trial 28 finished with value: 0.3034653824337937 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 5, 'linear_size_layer0': 140, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 290, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 100, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 190, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 140, 'linear_batchnorm_layer4': True, 'lr': 0.0002818905515729482, 'optimizer': 'AdamW', 'lr_lambda': 0.9125711089692021, 'batch_size': 16, 'epochs': 3}. Best is trial 12 with value: 0.29289246992544926.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:19:34,734]\u001b[0m Trial 29 finished with value: 0.2821419765241444 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 270, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 100, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 220, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 120, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 190, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 130, 'linear_batchnorm_layer6': False, 'lr': 0.0015408529745319748, 'optimizer': 'NAdam', 'lr_lambda': 0.8623755334584104, 'batch_size': 96, 'epochs': 3}. Best is trial 29 with value: 0.2821419765241444.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:19:40,569]\u001b[0m Trial 30 finished with value: 0.27156640170142055 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 260, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 230, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 200, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 220, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 100, 'linear_batchnorm_layer6': False, 'lr': 0.00022573088109855829, 'optimizer': 'Adam', 'lr_lambda': 0.8594695239720382, 'batch_size': 96, 'epochs': 2}. Best is trial 30 with value: 0.27156640170142055.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:19:46,491]\u001b[0m Trial 31 finished with value: 0.2807644638232887 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 260, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 140, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 230, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 200, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 190, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 100, 'linear_batchnorm_layer6': False, 'lr': 0.0013076170628071454, 'optimizer': 'Adam', 'lr_lambda': 0.860336428624645, 'batch_size': 96, 'epochs': 2}. Best is trial 30 with value: 0.27156640170142055.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:19:52,435]\u001b[0m Trial 32 finished with value: 0.2702315403148532 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 260, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 120, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 240, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 230, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 190, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 100, 'linear_batchnorm_layer6': False, 'lr': 0.00020915425593531133, 'optimizer': 'Adam', 'lr_lambda': 0.8629079747107674, 'batch_size': 96, 'epochs': 2}. Best is trial 32 with value: 0.2702315403148532.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:00,739]\u001b[0m Trial 33 finished with value: 0.27377775544300675 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 7, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 260, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 120, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 240, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 230, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 220, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 100, 'linear_batchnorm_layer6': False, 'lr': 0.00019913134689396696, 'optimizer': 'Adam', 'lr_lambda': 0.7789204548122753, 'batch_size': 96, 'epochs': 2}. Best is trial 32 with value: 0.2702315403148532.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:07,969]\u001b[0m Trial 34 finished with value: 0.2664862386882305 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 6, 'linear_size_layer0': 110, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 220, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 250, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 220, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 220, 'linear_batchnorm_layer5': False, 'lr': 0.00021677436519262322, 'optimizer': 'Adam', 'lr_lambda': 0.7688287581465718, 'batch_size': 96, 'epochs': 2}. Best is trial 34 with value: 0.2664862386882305.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:13,812]\u001b[0m Trial 35 finished with value: 0.26744021428748965 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 6, 'linear_size_layer0': 110, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 200, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 260, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 230, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 230, 'linear_batchnorm_layer5': False, 'lr': 0.00017772077824540212, 'optimizer': 'Adam', 'lr_lambda': 0.7644448425233197, 'batch_size': 96, 'epochs': 2}. Best is trial 34 with value: 0.2664862386882305.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:19,910]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:25,770]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:34,296]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:41,209]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:44,519]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:50,407]\u001b[0m Trial 41 finished with value: 0.27839886536821723 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 7, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 250, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 120, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 250, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 220, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 220, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 100, 'linear_batchnorm_layer6': False, 'lr': 0.00023701215304788455, 'optimizer': 'Adam', 'lr_lambda': 0.8004180657859796, 'batch_size': 96, 'epochs': 2}. Best is trial 34 with value: 0.2664862386882305.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:20:56,498]\u001b[0m Trial 42 finished with value: 0.26553132522989203 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 6, 'linear_size_layer0': 120, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 230, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 130, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 240, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 220, 'linear_batchnorm_layer4': True, 'linear_size_layer5': 230, 'linear_batchnorm_layer5': False, 'lr': 0.00019019679494352784, 'optimizer': 'Adam', 'lr_lambda': 0.7876615576632222, 'batch_size': 112, 'epochs': 2}. Best is trial 42 with value: 0.26553132522989203.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:03,183]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:11,951]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:18,233]\u001b[0m Trial 45 finished with value: 0.2694441252633145 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 6, 'linear_size_layer0': 250, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 230, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 180, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 260, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 210, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 270, 'linear_batchnorm_layer5': False, 'lr': 0.0001074009965049893, 'optimizer': 'Adam', 'lr_lambda': 0.8077316920183883, 'batch_size': 80, 'epochs': 2}. Best is trial 42 with value: 0.26553132522989203.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:24,355]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:27,640]\u001b[0m Trial 47 finished with value: 0.2797650263497704 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 6, 'linear_size_layer0': 240, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 200, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 180, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 260, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 180, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 280, 'linear_batchnorm_layer5': False, 'lr': 9.416056561802928e-05, 'optimizer': 'Adam', 'lr_lambda': 0.8145933232841691, 'batch_size': 80, 'epochs': 1}. Best is trial 42 with value: 0.26553132522989203.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:33,659]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:43,704]\u001b[0m Trial 49 finished with value: 0.270239401687967 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 140, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 220, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 210, 'linear_batchnorm_layer4': False, 'lr': 0.00041069753113366723, 'optimizer': 'Adagrad', 'lr_lambda': 0.7820543945221428, 'batch_size': 64, 'epochs': 2}. Best is trial 42 with value: 0.26553132522989203.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:49,660]\u001b[0m Trial 50 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:21:56,474]\u001b[0m Trial 51 finished with value: 0.2607403422923798 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 140, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 220, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 210, 'linear_batchnorm_layer4': False, 'lr': 0.00044265284437888997, 'optimizer': 'Adagrad', 'lr_lambda': 0.7858235597868477, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:03,268]\u001b[0m Trial 52 finished with value: 0.27050212881666547 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 130, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 180, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 210, 'linear_batchnorm_layer4': False, 'lr': 0.0009479010089087393, 'optimizer': 'Adagrad', 'lr_lambda': 0.7375031348301477, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:13,481]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:20,217]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:25,921]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:32,080]\u001b[0m Trial 56 finished with value: 0.269900922320391 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 140, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 250, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 140, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.000901051001109536, 'optimizer': 'Adam', 'lr_lambda': 0.646327257819757, 'batch_size': 80, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:38,302]\u001b[0m Trial 57 finished with value: 0.2741333391321333 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 150, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 240, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 180, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.0007735731800992654, 'optimizer': 'Adam', 'lr_lambda': 0.6343539558751217, 'batch_size': 80, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:43,676]\u001b[0m Trial 58 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:51,307]\u001b[0m Trial 59 finished with value: 0.2635603131766015 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 240, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.0004796526599797626, 'optimizer': 'Adam', 'lr_lambda': 0.6462008910315602, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:22:57,376]\u001b[0m Trial 60 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:04,007]\u001b[0m Trial 61 finished with value: 0.26750502053727493 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 240, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.0008840942919843557, 'optimizer': 'Adam', 'lr_lambda': 0.6599072627659839, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:10,866]\u001b[0m Trial 62 finished with value: 0.2648460700156841 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 230, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 200, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.0003627125212446121, 'optimizer': 'Adam', 'lr_lambda': 0.7097022983569428, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:21,142]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:27,626]\u001b[0m Trial 64 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:34,313]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:40,800]\u001b[0m Trial 66 finished with value: 0.26454744218511783 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 160, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'lr': 0.0003688054256853931, 'optimizer': 'Adam', 'lr_lambda': 0.5945236090998011, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:50,942]\u001b[0m Trial 67 finished with value: 0.26602958586621794 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 200, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 150, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 180, 'linear_batchnorm_layer4': False, 'lr': 0.0003802141497799726, 'optimizer': 'Adam', 'lr_lambda': 0.5536002966384443, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:23:57,271]\u001b[0m Trial 68 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:03,978]\u001b[0m Trial 69 finished with value: 0.26780504059223903 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 160, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 140, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 160, 'linear_batchnorm_layer4': False, 'lr': 0.000544886927148762, 'optimizer': 'Adagrad', 'lr_lambda': 0.5070118943138832, 'batch_size': 48, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:10,530]\u001b[0m Trial 70 finished with value: 0.2787758188044771 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 200, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 160, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.0021903257551891403, 'optimizer': 'Adam', 'lr_lambda': 0.5965384447806922, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:19,211]\u001b[0m Trial 71 finished with value: 0.2640391540654162 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 150, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 270, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 190, 'linear_batchnorm_layer4': False, 'lr': 0.00020030384938635285, 'optimizer': 'Adam', 'lr_lambda': 0.5735024367982383, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:27,242]\u001b[0m Trial 72 finished with value: 0.26690606978979514 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 130, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 130, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 180, 'linear_batchnorm_layer4': False, 'lr': 0.00036128638966180054, 'optimizer': 'Adam', 'lr_lambda': 0.5347962961117322, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:33,748]\u001b[0m Trial 73 finished with value: 0.2788781390545216 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 220, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 150, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 270, 'linear_batchnorm_layer3': False, 'lr': 0.0011272982549170466, 'optimizer': 'Adam', 'lr_lambda': 0.5793044023005842, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:40,629]\u001b[0m Trial 74 finished with value: 0.2656491164650236 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 240, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 140, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 190, 'linear_batchnorm_layer4': False, 'lr': 7.507619587486357e-05, 'optimizer': 'Adam', 'lr_lambda': 0.6266207966726646, 'batch_size': 48, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:47,715]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:24:57,793]\u001b[0m Trial 76 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:04,655]\u001b[0m Trial 77 finished with value: 0.27555457396166666 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 5, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 150, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 130, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'linear_size_layer4': 180, 'linear_batchnorm_layer4': False, 'lr': 0.0006383753489608371, 'optimizer': 'Adam', 'lr_lambda': 0.5393451931098946, 'batch_size': 48, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:11,209]\u001b[0m Trial 78 finished with value: 0.2611121969654205 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 150, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.00016377715153714355, 'optimizer': 'AdamW', 'lr_lambda': 0.6133315356798129, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:17,759]\u001b[0m Trial 79 finished with value: 0.26437045792315866 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.00015339546950208832, 'optimizer': 'AdamW', 'lr_lambda': 0.6148041516824687, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:27,962]\u001b[0m Trial 80 finished with value: 0.26817759808073655 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 190, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 190, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.00025013021096616077, 'optimizer': 'AdamW', 'lr_lambda': 0.6105969251485132, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:34,268]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:40,823]\u001b[0m Trial 82 finished with value: 0.2648501643475066 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'lr': 0.00017381571097724782, 'optimizer': 'AdamW', 'lr_lambda': 0.5741540018794754, 'batch_size': 64, 'epochs': 2}. Best is trial 51 with value: 0.2607403422923798.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:47,331]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:25:55,392]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:03,253]\u001b[0m Trial 85 finished with value: 0.258455013366122 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 130, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.00030123940814154353, 'optimizer': 'AdamW', 'lr_lambda': 0.6093962250032199, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:09,365]\u001b[0m Trial 86 finished with value: 0.2738006448275165 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 130, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.0016429948986826737, 'optimizer': 'AdamW', 'lr_lambda': 0.6076022134113601, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:15,375]\u001b[0m Trial 87 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:21,471]\u001b[0m Trial 88 finished with value: 0.26174793078711156 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 200, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.0002658228106845452, 'optimizer': 'AdamW', 'lr_lambda': 0.5862630613184588, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:31,139]\u001b[0m Trial 89 finished with value: 0.26252622353403193 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 200, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 220, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.0002939446460758242, 'optimizer': 'AdamW', 'lr_lambda': 0.5974920107888837, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:37,211]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:43,324]\u001b[0m Trial 91 finished with value: 0.2655536732391307 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 190, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 130, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 220, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.0002910004176239269, 'optimizer': 'AdamW', 'lr_lambda': 0.6251720069709858, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:49,504]\u001b[0m Trial 92 finished with value: 0.2602916540283906 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 230, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 300, 'linear_batchnorm_layer3': False, 'lr': 0.0002998136640072914, 'optimizer': 'AdamW', 'lr_lambda': 0.6379331481569002, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:26:55,606]\u001b[0m Trial 93 finished with value: 0.2613084602512811 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 200, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 240, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 290, 'linear_batchnorm_layer3': False, 'lr': 0.0002862327937487058, 'optimizer': 'AdamW', 'lr_lambda': 0.6389571573258218, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:27:05,503]\u001b[0m Trial 94 finished with value: 0.2606868081186947 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 200, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 100, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 230, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.000259174723705573, 'optimizer': 'AdamW', 'lr_lambda': 0.6369978408014932, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:27:11,551]\u001b[0m Trial 95 pruned. \u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:27:17,746]\u001b[0m Trial 96 finished with value: 0.27386622993569626 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 190, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 100, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 230, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 270, 'linear_batchnorm_layer3': False, 'lr': 0.0002704889221733195, 'optimizer': 'AdamW', 'lr_lambda': 0.6523461505740701, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:27:23,906]\u001b[0m Trial 97 finished with value: 0.26564343352066844 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 4, 'linear_size_layer0': 220, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 240, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 280, 'linear_batchnorm_layer3': False, 'lr': 0.0004879864510896078, 'optimizer': 'AdamW', 'lr_lambda': 0.6326169340250456, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:27:31,408]\u001b[0m Trial 98 finished with value: 0.26848591040623815 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 3, 'linear_size_layer0': 230, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 220, 'linear_batchnorm_layer2': True, 'lr': 0.0012800223567729211, 'optimizer': 'AdamW', 'lr_lambda': 0.6820227470252993, 'batch_size': 80, 'epochs': 2}. Best is trial 85 with value: 0.258455013366122.\u001b[0m\n",
      "\u001b[32m[I 2022-09-22 16:27:39,798]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value:  0.258455013366122\n",
      " Params: \n",
      "     activation_lin: ReLU\n",
      "     batch_size: 80\n",
      "     epochs: 2\n",
      "     linear_batchnorm_layer0: False\n",
      "     linear_batchnorm_layer1: False\n",
      "     linear_batchnorm_layer2: True\n",
      "     linear_batchnorm_layer3: False\n",
      "     linear_size_layer0: 210\n",
      "     linear_size_layer1: 130\n",
      "     linear_size_layer2: 170\n",
      "     linear_size_layer3: 280\n",
      "     lr: 0.00030123940814154353\n",
      "     lr_lambda: 0.6093962250032199\n",
      "     n_layers_linear: 4\n",
      "     optimizer: AdamW\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\" Value: \", trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"     {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with hyperparameters computed by optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_optimized(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN_optimized, self).__init__()\n",
    "        self.linear = nn.Sequential()\n",
    "        linear_in = 2314\n",
    "\n",
    "\n",
    "        self.linear.append(nn.Linear(linear_in, 210))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(210, 130))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(130, 170))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(170, 280))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(280, 1))\n",
    "        self.linear.append(nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN_optimized().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "lr = 0.00030123940814154353\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_lambda = 0.6093962250032199 \n",
    "batch_size = 80\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: lr_lambda)\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def get_amex(pred, y):\n",
    "    pred_df = pd.DataFrame(pred, columns=[\"prediction\"])\n",
    "    target_df = pd.DataFrame(y, columns=[\"target\"])\n",
    "    uuid_df = pd.DataFrame(data={\"uuid\": [uuid.uuid4() for _ in range(len(pred_df.index))]})\n",
    "    pred_df = pd.concat([uuid_df, pred_df], axis=1)\n",
    "    target_df = pd.concat([uuid_df, target_df], axis=1)\n",
    "    amex_metric_value = amex_metric(target_df, pred_df)\n",
    "    return amex_metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ration = 0.7\n",
    "full_dataset = AmericanExpressPreprocessedProfileTimeSeriesDataset(\"./amex_preprocessed.npz\")\n",
    "\n",
    "train_size = int(train_test_ration * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, writer, test_dataset):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global train_loop_num\n",
    "        train_loop_num += 1\n",
    "        writer.add_scalar('BatchLoss/train', loss, train_loop_num)\n",
    "        if batch % 100 == 0 and batch != 0:\n",
    "            test_loss = test_loop(test_dataloader, model, loss_fn, test_dataset)\n",
    "            writer.add_scalar('Loss/test', test_loss, train_loop_num)   \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 16:33:23.193760: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-22 16:33:23.397291: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-22 16:33:23.397334: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-22 16:33:23.437463: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-22 16:33:24.314889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-22 16:33:24.315025: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-22 16:33:24.315038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    writer = SummaryWriter(log_dir=\"runs_fcn\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, writer, test_dataset)\n",
    "    models[t] = model\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = AmericanExpressPreprocessedProfileTimeSeriesDataset(\"./amex_preprocessed.npz\", test=True)\n",
    "test_dataloader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.Tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        pred = model(X)\n",
    "        res = torch.cat((res, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.cpu().numpy()\n",
    "res = pd.DataFrame(res)\n",
    "res.to_csv('pred_fcn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./amex_preprocessed.npz\")\n",
    "y = data[\"test_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12611.959124\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(res - y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a2c4b191d1ae843dde5cb5f4d1f62fa892f6b79b0f9392a84691e890e33c5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
