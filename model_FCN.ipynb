{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import math\n",
    "import time\n",
    "import uuid\n",
    "import optuna\n",
    "import plotly\n",
    "import matplotlib\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datloader for the amex dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmericanExpressPreprocessedProfileTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, dataset_file, test=False, nrows=False, transformation=False):\n",
    "        data = np.load(dataset_file)\n",
    "        if not test:\n",
    "            num_data = data[\"train_floats\"].reshape(data[\"train_floats\"].shape[0], -1, 13)\n",
    "            cat_data = data[\"train_cat\"].reshape(data[\"train_cat\"].shape[0], -1, 13)\n",
    "            self.y = data[\"train_y\"]\n",
    "        else:\n",
    "            num_data = data[\"test_floats\"].reshape(data[\"test_floats\"].shape[0], -1, 13)\n",
    "            cat_data = data[\"test_cat\"].reshape(data[\"test_cat\"].shape[0], -1, 13)\n",
    "            self.y = np.zeros(num_data.shape[0])#data[\"test_y\"]\n",
    "\n",
    "        if nrows:\n",
    "            num_data = num_data[0:nrows]\n",
    "            cat_data = cat_data[0:nrows]\n",
    "            self.y = self.y[0:nrows]\n",
    "\n",
    "        self.dataset = np.concatenate([num_data, cat_data], axis=1)\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        data = torch.tensor(data, dtype=torch.float32, requires_grad=True)\n",
    "        label = torch.tensor([label], dtype=torch.float32)\n",
    "        label = label.to(device)\n",
    "        data = data.to(device)\n",
    "        if self.transformation: data = self.transformation(data)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN for time series classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, trial):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        self.trial = trial\n",
    "\n",
    "        lin_activation = trial.suggest_categorical(f\"activation_lin\", [\"LeakyReLU\", \"ReLU\", \"ELU\"])\n",
    "        self.lin_activ = getattr(nn, lin_activation)()\n",
    "\n",
    "        self.linear = nn.Sequential()\n",
    "        linear_in = 2314\n",
    "        n_layers_linear = self.trial.suggest_int(\"n_layers_linear\", 1, 10)\n",
    "        for k in range(n_layers_linear):\n",
    "            linear_out = self.trial.suggest_int(f\"linear_size_layer{k}\", 100, 300, 10)\n",
    "            self.linear.append(nn.Linear(linear_in, linear_out))\n",
    "            self.linear.append(self.lin_activ)\n",
    "            batchnorm = self.trial.suggest_categorical(f\"linear_batchnorm_layer{k}\", [True, False])            \n",
    "            if batchnorm: self.linear.append(nn.BatchNorm1d(linear_out))\n",
    "\n",
    "            linear_in = linear_out\n",
    "        self.linear.append(nn.Linear(linear_out, 1))\n",
    "        self.linear.append(nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred = torch.round(pred)\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ration = 0.7\n",
    "full_dataset = AmericanExpressPreprocessedProfileTimeSeriesDataset(\"./amex_preprocessed.npz\", nrows=10000)\n",
    "\n",
    "train_size = int(train_test_ration * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    model = FCN(trial).to(device)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    lr = trial.suggest_float(\"lr\", 1e-7, 0.1, log=True)\n",
    "    optim_ = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"Adam\", \"SGD\", \"Adagrad\", \"NAdam\"])\n",
    "    optimizer = getattr(optim, optim_)(model.parameters(), lr=lr)\n",
    "    lr_lambda = trial.suggest_float(\"lr_lambda\", 0.4, 0.99)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 128, 16)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: lr_lambda)\n",
    "    epochs = trial.suggest_int(\"epochs\", 1, 3)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
    "        loss = test_loop(test_dataloader, model, loss_fn, t)\n",
    "        trial.report(loss, t)\n",
    "        scheduler.step()\n",
    "\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-25 12:18:29,078]\u001b[0m A new study created in RDB with name: optuna-study-linear\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"optuna-study-linear\", direction=\"minimize\", storage='sqlite:///optuna-study-linear.db', load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-25 12:18:33,557]\u001b[0m Trial 0 finished with value: 0.7767959700690376 and parameters: {'activation_lin': 'ELU', 'n_layers_linear': 3, 'linear_size_layer0': 250, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 150, 'linear_batchnorm_layer1': False, 'linear_size_layer2': 170, 'linear_batchnorm_layer2': True, 'lr': 2.664125370807947e-06, 'optimizer': 'SGD', 'lr_lambda': 0.7185788573513253, 'batch_size': 48, 'epochs': 1}. Best is trial 0 with value: 0.7767959700690376.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 12:18:35,633]\u001b[0m Trial 1 finished with value: 0.33902112974060905 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 10, 'linear_size_layer0': 220, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 110, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 200, 'linear_batchnorm_layer2': True, 'linear_size_layer3': 110, 'linear_batchnorm_layer3': True, 'linear_size_layer4': 160, 'linear_batchnorm_layer4': False, 'linear_size_layer5': 250, 'linear_batchnorm_layer5': False, 'linear_size_layer6': 170, 'linear_batchnorm_layer6': True, 'linear_size_layer7': 140, 'linear_batchnorm_layer7': True, 'linear_size_layer8': 270, 'linear_batchnorm_layer8': True, 'linear_size_layer9': 170, 'linear_batchnorm_layer9': True, 'lr': 0.037974909996951585, 'optimizer': 'Adagrad', 'lr_lambda': 0.5956550395806045, 'batch_size': 112, 'epochs': 1}. Best is trial 1 with value: 0.33902112974060905.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 12:18:40,330]\u001b[0m Trial 2 finished with value: 0.49538064510264296 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 3, 'linear_size_layer0': 240, 'linear_batchnorm_layer0': True, 'linear_size_layer1': 180, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 160, 'linear_batchnorm_layer2': False, 'lr': 0.0007734187399839502, 'optimizer': 'SGD', 'lr_lambda': 0.8834515809853438, 'batch_size': 64, 'epochs': 3}. Best is trial 1 with value: 0.33902112974060905.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 12:18:41,838]\u001b[0m Trial 3 finished with value: 0.36688091792166233 and parameters: {'activation_lin': 'ReLU', 'n_layers_linear': 1, 'linear_size_layer0': 210, 'linear_batchnorm_layer0': True, 'lr': 0.058740800287884004, 'optimizer': 'NAdam', 'lr_lambda': 0.5728073999168664, 'batch_size': 128, 'epochs': 1}. Best is trial 1 with value: 0.33902112974060905.\u001b[0m\n",
      "\u001b[32m[I 2022-09-25 12:18:46,647]\u001b[0m Trial 4 finished with value: 0.31467686869479994 and parameters: {'activation_lin': 'LeakyReLU', 'n_layers_linear': 4, 'linear_size_layer0': 100, 'linear_batchnorm_layer0': False, 'linear_size_layer1': 120, 'linear_batchnorm_layer1': True, 'linear_size_layer2': 260, 'linear_batchnorm_layer2': False, 'linear_size_layer3': 250, 'linear_batchnorm_layer3': True, 'lr': 0.008116098004782892, 'optimizer': 'Adam', 'lr_lambda': 0.9457504861456585, 'batch_size': 112, 'epochs': 3}. Best is trial 4 with value: 0.31467686869479994.\u001b[0m\n",
      "\u001b[33m[W 2022-09-25 12:18:53,239]\u001b[0m Trial 5 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_586512/492981689.py\", line 15, in objective\n",
      "    train_loop(train_dataloader, model, loss_fn, optimizer, t)\n",
      "  File \"/tmp/ipykernel_586512/1988164781.py\", line 9, in train_loop\n",
      "    loss.backward()\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.9/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/ubuntu/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     _optimize(\n\u001b[1;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    429\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 12\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m epochs \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer, t)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     loss \u001b[39m=\u001b[39m test_loop(test_dataloader, model, loss_fn, t)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     trial\u001b[39m.\u001b[39mreport(loss, t)\n",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, epoch)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      " Value:  0.25591892500718433\n",
      " Params: \n",
      "     activation_lin: ReLU\n",
      "     batch_size: 112\n",
      "     epochs: 2\n",
      "     linear_batchnorm_layer0: False\n",
      "     linear_batchnorm_layer1: False\n",
      "     linear_size_layer0: 1370\n",
      "     linear_size_layer1: 880\n",
      "     lr: 0.001051905292972931\n",
      "     lr_lambda: 0.6837203763543799\n",
      "     n_layers_linear: 2\n",
      "     optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\" Value: \", trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"     {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with hyperparameters computed by optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_optimized(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN_optimized, self).__init__()\n",
    "        self.linear = nn.Sequential()\n",
    "        linear_in = 2314\n",
    "\n",
    "\n",
    "        self.linear.append(nn.Linear(linear_in, 210))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(210, 130))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(130, 170))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(170, 280))\n",
    "        self.linear.append(nn.ReLU())\n",
    "\n",
    "        self.linear.append(nn.Linear(280, 1))\n",
    "        self.linear.append(nn.Sigmoid())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN_optimized().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "lr = 0.00030123940814154353\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_lambda = 0.6093962250032199 \n",
    "batch_size = 80\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: lr_lambda)\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def get_amex(pred, y):\n",
    "    pred_df = pd.DataFrame(pred, columns=[\"prediction\"])\n",
    "    target_df = pd.DataFrame(y, columns=[\"target\"])\n",
    "    uuid_df = pd.DataFrame(data={\"uuid\": [uuid.uuid4() for _ in range(len(pred_df.index))]})\n",
    "    pred_df = pd.concat([uuid_df, pred_df], axis=1)\n",
    "    target_df = pd.concat([uuid_df, target_df], axis=1)\n",
    "    amex_metric_value = amex_metric(target_df, pred_df)\n",
    "    return amex_metric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loop_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ration = 0.7\n",
    "full_dataset = AmericanExpressPreprocessedProfileTimeSeriesDataset(\"./amex_preprocessed.npz\")\n",
    "\n",
    "train_size = int(train_test_ration * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            pred = torch.round(pred)\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, writer, test_dataset):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global train_loop_num\n",
    "        train_loop_num += 1\n",
    "        writer.add_scalar('BatchLoss/train', loss, train_loop_num)\n",
    "        if batch % 100 == 0 and batch != 0:\n",
    "            test_loss = test_loop(test_dataloader, model, loss_fn, test_dataset)\n",
    "            writer.add_scalar('Loss/test', test_loss, train_loop_num)   \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     writer \u001b[39m=\u001b[39m SummaryWriter(log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mruns_fcn/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(t))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     train_loop(train_dataloader, model, loss_fn, optimizer, writer, test_dataset)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     models[t] \u001b[39m=\u001b[39m model\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 24\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, writer, test_dataset)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mBatchLoss/train\u001b[39m\u001b[39m'\u001b[39m, loss, train_loop_num)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m batch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m batch \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         test_loss \u001b[39m=\u001b[39m test_loop(test_dataloader, model, loss_fn, test_dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mLoss/test\u001b[39m\u001b[39m'\u001b[39m, test_loss, train_loop_num)   \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 24\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, loss_fn, epoch)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m test_loss, correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(pred, y)\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 290\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "\u001b[1;32m/home/ubuntu/AML/jonas_model_FCN.ipynb Cell 24\u001b[0m in \u001b[0;36mAmericanExpressPreprocessedProfileTimeSeriesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my[idx]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(data, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32, requires_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([label], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2244656e6269416d6f734f776e227d/home/ubuntu/AML/jonas_model_FCN.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    writer = SummaryWriter(log_dir=\"runs_fcn/\"+str(t))\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, writer, test_dataset)\n",
    "    models[t] = model\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(models[6], \"model_fcn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = models[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = AmericanExpressPreprocessedProfileTimeSeriesDataset(\"./amex_preprocessed.npz\", test=True)\n",
    "test_dataloader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.Tensor([]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        pred = model_(X)\n",
    "        res = torch.cat((res, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.cpu().numpy()\n",
    "res = pd.DataFrame(res)\n",
    "res.to_csv('pred_fcn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./amex_preprocessed.npz\")\n",
    "y = data[\"test_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(res - y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a2c4b191d1ae843dde5cb5f4d1f62fa892f6b79b0f9392a84691e890e33c5a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
